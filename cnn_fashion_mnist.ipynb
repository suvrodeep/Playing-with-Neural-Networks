{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd60c17-7e45-47bf-8d63-cae5207feadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbc1ff1-e154-4773-b964-5db6f42ba0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a6d1b6-29dd-4371-b623-b3ef6656447e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dimensions of image\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53e639c-c105-4446-8483-0a11b6725740",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5322c25ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View a sample image\n",
    "plt.imshow(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825b240a-79b2-4a93-a5af-ba572a7e05f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Explore training data and labels\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e555217-4097-41b6-a5b9-b2a4b192ed17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9e6bb6-db49-4174-b215-8105e7a4a771",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da912ef1-d89e-4887-82ad-89a51d171c28",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac4e050-9507-475e-9dde-c40af00a680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:(60000, 28, 28)\n",
      "Test data shape:(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape:{}\".format(x_train.shape))\n",
    "print(\"Test data shape:{}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ec09f9-88aa-4020-a5d6-7a25c09436fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes training labels:10\n",
      "Unique values in training labels:[9 0 3 2 7 5 1 6 4 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes training labels:{}\".format(len(pd.unique(y_train))))\n",
    "print(\"Unique values in training labels:{}\".format(pd.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a95fde-a514-4fc7-be02-62a2b1087df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image pixel values\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272ba56c-c05c-44a7-8135-0cc0ef34a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare one-hot encoded y-values\n",
    "y_train_cat = keras.utils.to_categorical(y=y_train, num_classes=10)\n",
    "y_test_cat = keras.utils.to_categorical(y=y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e76aad5-bf76-4f47-8c67-9ec02e566adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping data to batch_size, width, height, color_channel\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9858381-a719-448b-a03e-40714438b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare GPU\n",
    "def prep_devices():\n",
    "    phy_gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "    \n",
    "    for gpu in phy_gpus:\n",
    "        tf.config.experimental.set_memory_growth(device=gpu, enable=True)\n",
    "\n",
    "    log_gpus = tf.config.list_logical_devices(device_type='GPU')\n",
    "    phy_cpus = tf.config.list_physical_devices(device_type='CPU')\n",
    "    log_cpus = tf.config.list_logical_devices(device_type='CPU')\n",
    "\n",
    "    print(\"Physical GPUs: {}\\tLogical GPUs: {}\\nPhysical CPUs: {}\\tLogical CPUs: {}\".format(len(phy_gpus),\n",
    "                                                                                             len(log_gpus),\n",
    "                                                                                             len(phy_cpus),\n",
    "                                                                                             len(log_cpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d65e6c-8155-4f8c-a23b-62b0087496ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical GPUs: 0\tLogical GPUs: 0\n",
      "Physical CPUs: 1\tLogical CPUs: 1\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "prep_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "746cc73f-60fe-41ff-a869-6503014de9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def model_func(clear_session=True):\n",
    "    if clear_session:\n",
    "        backend.clear_session()\n",
    "            \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feba245c-3e22-4d6a-bb91-af05171f9640",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 61,482\n",
      "Trainable params: 61,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 1.2171 - accuracy: 0.5494 - val_loss: 0.6575 - val_accuracy: 0.7540\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.7432 - accuracy: 0.7280 - val_loss: 0.5524 - val_accuracy: 0.7917\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.6495 - accuracy: 0.7597 - val_loss: 0.4897 - val_accuracy: 0.8117\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.6026 - accuracy: 0.7743 - val_loss: 0.4622 - val_accuracy: 0.8268\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.5692 - accuracy: 0.7919 - val_loss: 0.4450 - val_accuracy: 0.8355\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.5494 - accuracy: 0.7982 - val_loss: 0.4263 - val_accuracy: 0.8485\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.5281 - accuracy: 0.8059 - val_loss: 0.4160 - val_accuracy: 0.8522\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.5117 - accuracy: 0.8130 - val_loss: 0.3921 - val_accuracy: 0.8565\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4991 - accuracy: 0.8179 - val_loss: 0.3768 - val_accuracy: 0.8643\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4925 - accuracy: 0.8212 - val_loss: 0.3761 - val_accuracy: 0.8665\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4773 - accuracy: 0.8267 - val_loss: 0.3620 - val_accuracy: 0.8677\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4647 - accuracy: 0.8309 - val_loss: 0.3575 - val_accuracy: 0.8747\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4582 - accuracy: 0.8332 - val_loss: 0.3551 - val_accuracy: 0.8690\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4513 - accuracy: 0.8383 - val_loss: 0.3414 - val_accuracy: 0.8760\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4448 - accuracy: 0.8390 - val_loss: 0.3372 - val_accuracy: 0.8780\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4410 - accuracy: 0.8412 - val_loss: 0.3295 - val_accuracy: 0.8780\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.4296 - accuracy: 0.8466 - val_loss: 0.3265 - val_accuracy: 0.8827\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.4231 - accuracy: 0.8481 - val_loss: 0.3260 - val_accuracy: 0.8798\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.4226 - accuracy: 0.8481 - val_loss: 0.3221 - val_accuracy: 0.8775\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4144 - accuracy: 0.8500 - val_loss: 0.3171 - val_accuracy: 0.8832\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.4078 - accuracy: 0.8525 - val_loss: 0.3130 - val_accuracy: 0.8857\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.4012 - accuracy: 0.8557 - val_loss: 0.3083 - val_accuracy: 0.8853\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.4002 - accuracy: 0.8560 - val_loss: 0.3099 - val_accuracy: 0.8853\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.3947 - accuracy: 0.8572 - val_loss: 0.3030 - val_accuracy: 0.8883\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.3915 - accuracy: 0.8586 - val_loss: 0.2983 - val_accuracy: 0.8923\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.3890 - accuracy: 0.8611 - val_loss: 0.3006 - val_accuracy: 0.8893\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.3854 - accuracy: 0.8611 - val_loss: 0.2936 - val_accuracy: 0.8928\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.3801 - accuracy: 0.8624 - val_loss: 0.2917 - val_accuracy: 0.8915\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3770 - accuracy: 0.8623 - val_loss: 0.2893 - val_accuracy: 0.8943\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3725 - accuracy: 0.8658 - val_loss: 0.2934 - val_accuracy: 0.8908\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3718 - accuracy: 0.8646 - val_loss: 0.2855 - val_accuracy: 0.8938\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3660 - accuracy: 0.8681 - val_loss: 0.2827 - val_accuracy: 0.8925\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3630 - accuracy: 0.8683 - val_loss: 0.2800 - val_accuracy: 0.8952\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3576 - accuracy: 0.8705 - val_loss: 0.2773 - val_accuracy: 0.8970\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.3609 - accuracy: 0.8707 - val_loss: 0.2776 - val_accuracy: 0.8973\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.3554 - accuracy: 0.8717 - val_loss: 0.2779 - val_accuracy: 0.8972\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3498 - accuracy: 0.8732 - val_loss: 0.2714 - val_accuracy: 0.8985\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3506 - accuracy: 0.8721 - val_loss: 0.2750 - val_accuracy: 0.8978\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3486 - accuracy: 0.8722 - val_loss: 0.2683 - val_accuracy: 0.9015\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3441 - accuracy: 0.8769 - val_loss: 0.2700 - val_accuracy: 0.8982\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3406 - accuracy: 0.8757 - val_loss: 0.2669 - val_accuracy: 0.9032\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3413 - accuracy: 0.8749 - val_loss: 0.2645 - val_accuracy: 0.9017\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3374 - accuracy: 0.8761 - val_loss: 0.2670 - val_accuracy: 0.9012\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3370 - accuracy: 0.8783 - val_loss: 0.2642 - val_accuracy: 0.9028\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3343 - accuracy: 0.8779 - val_loss: 0.2638 - val_accuracy: 0.9043\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3359 - accuracy: 0.8788 - val_loss: 0.2652 - val_accuracy: 0.9010\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3274 - accuracy: 0.8816 - val_loss: 0.2596 - val_accuracy: 0.9037\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3287 - accuracy: 0.8809 - val_loss: 0.2580 - val_accuracy: 0.9038\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3271 - accuracy: 0.8801 - val_loss: 0.2665 - val_accuracy: 0.8978\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3254 - accuracy: 0.8800 - val_loss: 0.2555 - val_accuracy: 0.9035\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3230 - accuracy: 0.8820 - val_loss: 0.2596 - val_accuracy: 0.9023\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3216 - accuracy: 0.8821 - val_loss: 0.2566 - val_accuracy: 0.9043\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3180 - accuracy: 0.8842 - val_loss: 0.2563 - val_accuracy: 0.9060\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3179 - accuracy: 0.8844 - val_loss: 0.2548 - val_accuracy: 0.9060\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3145 - accuracy: 0.8859 - val_loss: 0.2498 - val_accuracy: 0.9092\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3145 - accuracy: 0.8874 - val_loss: 0.2498 - val_accuracy: 0.9082\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3118 - accuracy: 0.8864 - val_loss: 0.2512 - val_accuracy: 0.9070\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3092 - accuracy: 0.8868 - val_loss: 0.2487 - val_accuracy: 0.9095\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3087 - accuracy: 0.8873 - val_loss: 0.2465 - val_accuracy: 0.9097\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3098 - accuracy: 0.8886 - val_loss: 0.2541 - val_accuracy: 0.9085\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.3048 - accuracy: 0.8885 - val_loss: 0.2514 - val_accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3038 - accuracy: 0.8892 - val_loss: 0.2458 - val_accuracy: 0.9108\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.3064 - accuracy: 0.8893 - val_loss: 0.2470 - val_accuracy: 0.9083\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.3027 - accuracy: 0.8893 - val_loss: 0.2568 - val_accuracy: 0.9083\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.3026 - accuracy: 0.8896 - val_loss: 0.2478 - val_accuracy: 0.9093\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 10s 90ms/step - loss: 0.3025 - accuracy: 0.8900 - val_loss: 0.2502 - val_accuracy: 0.9063\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 10s 89ms/step - loss: 0.2968 - accuracy: 0.8906 - val_loss: 0.2506 - val_accuracy: 0.9077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1844c266248>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model = model_func()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=5, restore_best_weights=True)\n",
    "model.fit(x=x_train, y=y_train_cat, epochs=100, validation_split=0.1, batch_size=500, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2294ef4f-5c96-4c1f-ab56-85e69bd8d482",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.208310</td>\n",
       "      <td>0.555093</td>\n",
       "      <td>0.673626</td>\n",
       "      <td>0.751333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.724074</td>\n",
       "      <td>0.563912</td>\n",
       "      <td>0.784500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.663429</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.507334</td>\n",
       "      <td>0.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.618117</td>\n",
       "      <td>0.770685</td>\n",
       "      <td>0.490706</td>\n",
       "      <td>0.807667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.585930</td>\n",
       "      <td>0.780019</td>\n",
       "      <td>0.464590</td>\n",
       "      <td>0.818167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.568235</td>\n",
       "      <td>0.787630</td>\n",
       "      <td>0.449592</td>\n",
       "      <td>0.828500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.551669</td>\n",
       "      <td>0.794944</td>\n",
       "      <td>0.438148</td>\n",
       "      <td>0.831833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.530673</td>\n",
       "      <td>0.802222</td>\n",
       "      <td>0.418337</td>\n",
       "      <td>0.843833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.516060</td>\n",
       "      <td>0.808870</td>\n",
       "      <td>0.406366</td>\n",
       "      <td>0.850667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.502943</td>\n",
       "      <td>0.812981</td>\n",
       "      <td>0.394833</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.818148</td>\n",
       "      <td>0.381583</td>\n",
       "      <td>0.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.481583</td>\n",
       "      <td>0.824259</td>\n",
       "      <td>0.372971</td>\n",
       "      <td>0.865667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.472292</td>\n",
       "      <td>0.827333</td>\n",
       "      <td>0.368795</td>\n",
       "      <td>0.860833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.459783</td>\n",
       "      <td>0.831926</td>\n",
       "      <td>0.363052</td>\n",
       "      <td>0.865833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.450905</td>\n",
       "      <td>0.835278</td>\n",
       "      <td>0.347353</td>\n",
       "      <td>0.868333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.442118</td>\n",
       "      <td>0.838444</td>\n",
       "      <td>0.343271</td>\n",
       "      <td>0.871500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.437423</td>\n",
       "      <td>0.839222</td>\n",
       "      <td>0.334898</td>\n",
       "      <td>0.872667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.428684</td>\n",
       "      <td>0.842889</td>\n",
       "      <td>0.326443</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.419591</td>\n",
       "      <td>0.847389</td>\n",
       "      <td>0.326612</td>\n",
       "      <td>0.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.415835</td>\n",
       "      <td>0.848593</td>\n",
       "      <td>0.318845</td>\n",
       "      <td>0.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.409024</td>\n",
       "      <td>0.851130</td>\n",
       "      <td>0.314121</td>\n",
       "      <td>0.882667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.401003</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.318051</td>\n",
       "      <td>0.882667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.400229</td>\n",
       "      <td>0.855056</td>\n",
       "      <td>0.311892</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.393045</td>\n",
       "      <td>0.857370</td>\n",
       "      <td>0.304679</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.389985</td>\n",
       "      <td>0.858352</td>\n",
       "      <td>0.298877</td>\n",
       "      <td>0.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.385148</td>\n",
       "      <td>0.860167</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.382203</td>\n",
       "      <td>0.863556</td>\n",
       "      <td>0.298929</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.374930</td>\n",
       "      <td>0.863870</td>\n",
       "      <td>0.291221</td>\n",
       "      <td>0.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.372501</td>\n",
       "      <td>0.866759</td>\n",
       "      <td>0.286122</td>\n",
       "      <td>0.893167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.366875</td>\n",
       "      <td>0.866389</td>\n",
       "      <td>0.286301</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.366870</td>\n",
       "      <td>0.868426</td>\n",
       "      <td>0.287294</td>\n",
       "      <td>0.889167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.359419</td>\n",
       "      <td>0.870481</td>\n",
       "      <td>0.279448</td>\n",
       "      <td>0.896167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.358921</td>\n",
       "      <td>0.871926</td>\n",
       "      <td>0.279099</td>\n",
       "      <td>0.897833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.355626</td>\n",
       "      <td>0.870074</td>\n",
       "      <td>0.277175</td>\n",
       "      <td>0.897167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.353973</td>\n",
       "      <td>0.872111</td>\n",
       "      <td>0.278568</td>\n",
       "      <td>0.897833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.351787</td>\n",
       "      <td>0.874093</td>\n",
       "      <td>0.272031</td>\n",
       "      <td>0.899833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.874278</td>\n",
       "      <td>0.274506</td>\n",
       "      <td>0.895500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.347034</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.272798</td>\n",
       "      <td>0.899333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.344142</td>\n",
       "      <td>0.876741</td>\n",
       "      <td>0.269356</td>\n",
       "      <td>0.896833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.339072</td>\n",
       "      <td>0.877111</td>\n",
       "      <td>0.267047</td>\n",
       "      <td>0.898833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.338045</td>\n",
       "      <td>0.876722</td>\n",
       "      <td>0.267141</td>\n",
       "      <td>0.899333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.332427</td>\n",
       "      <td>0.878796</td>\n",
       "      <td>0.266965</td>\n",
       "      <td>0.896833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.334323</td>\n",
       "      <td>0.878870</td>\n",
       "      <td>0.264638</td>\n",
       "      <td>0.898833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.327452</td>\n",
       "      <td>0.882019</td>\n",
       "      <td>0.266978</td>\n",
       "      <td>0.901167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.329465</td>\n",
       "      <td>0.880296</td>\n",
       "      <td>0.261013</td>\n",
       "      <td>0.901667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.325646</td>\n",
       "      <td>0.882944</td>\n",
       "      <td>0.259670</td>\n",
       "      <td>0.902333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.325089</td>\n",
       "      <td>0.882352</td>\n",
       "      <td>0.257204</td>\n",
       "      <td>0.901333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.322244</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>0.254368</td>\n",
       "      <td>0.903500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.321581</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.260035</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.314263</td>\n",
       "      <td>0.885704</td>\n",
       "      <td>0.257947</td>\n",
       "      <td>0.903833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.312574</td>\n",
       "      <td>0.885518</td>\n",
       "      <td>0.261191</td>\n",
       "      <td>0.900667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.885574</td>\n",
       "      <td>0.262736</td>\n",
       "      <td>0.904167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.313318</td>\n",
       "      <td>0.884963</td>\n",
       "      <td>0.257644</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.208310  0.555093  0.673626      0.751333\n",
       "1   0.743737  0.724074  0.563912      0.784500\n",
       "2   0.663429  0.754148  0.507334      0.803000\n",
       "3   0.618117  0.770685  0.490706      0.807667\n",
       "4   0.585930  0.780019  0.464590      0.818167\n",
       "5   0.568235  0.787630  0.449592      0.828500\n",
       "6   0.551669  0.794944  0.438148      0.831833\n",
       "7   0.530673  0.802222  0.418337      0.843833\n",
       "8   0.516060  0.808870  0.406366      0.850667\n",
       "9   0.502943  0.812981  0.394833      0.854167\n",
       "10  0.494734  0.818148  0.381583      0.861000\n",
       "11  0.481583  0.824259  0.372971      0.865667\n",
       "12  0.472292  0.827333  0.368795      0.860833\n",
       "13  0.459783  0.831926  0.363052      0.865833\n",
       "14  0.450905  0.835278  0.347353      0.868333\n",
       "15  0.442118  0.838444  0.343271      0.871500\n",
       "16  0.437423  0.839222  0.334898      0.872667\n",
       "17  0.428684  0.842889  0.326443      0.878000\n",
       "18  0.419591  0.847389  0.326612      0.878500\n",
       "19  0.415835  0.848593  0.318845      0.882500\n",
       "20  0.409024  0.851130  0.314121      0.882667\n",
       "21  0.401003  0.854037  0.318051      0.882667\n",
       "22  0.400229  0.855056  0.311892      0.888000\n",
       "23  0.393045  0.857370  0.304679      0.886500\n",
       "24  0.389985  0.858352  0.298877      0.885500\n",
       "25  0.385148  0.860167  0.295825      0.889000\n",
       "26  0.382203  0.863556  0.298929      0.888000\n",
       "27  0.374930  0.863870  0.291221      0.891500\n",
       "28  0.372501  0.866759  0.286122      0.893167\n",
       "29  0.366875  0.866389  0.286301      0.890000\n",
       "30  0.366870  0.868426  0.287294      0.889167\n",
       "31  0.359419  0.870481  0.279448      0.896167\n",
       "32  0.358921  0.871926  0.279099      0.897833\n",
       "33  0.355626  0.870074  0.277175      0.897167\n",
       "34  0.353973  0.872111  0.278568      0.897833\n",
       "35  0.351787  0.874093  0.272031      0.899833\n",
       "36  0.347266  0.874278  0.274506      0.895500\n",
       "37  0.347034  0.874222  0.272798      0.899333\n",
       "38  0.344142  0.876741  0.269356      0.896833\n",
       "39  0.339072  0.877111  0.267047      0.898833\n",
       "40  0.338045  0.876722  0.267141      0.899333\n",
       "41  0.332427  0.878796  0.266965      0.896833\n",
       "42  0.334323  0.878870  0.264638      0.898833\n",
       "43  0.327452  0.882019  0.266978      0.901167\n",
       "44  0.329465  0.880296  0.261013      0.901667\n",
       "45  0.325646  0.882944  0.259670      0.902333\n",
       "46  0.325089  0.882352  0.257204      0.901333\n",
       "47  0.322244  0.884093  0.254368      0.903500\n",
       "48  0.321581  0.882667  0.260035      0.904000\n",
       "49  0.314263  0.885704  0.257947      0.903833\n",
       "50  0.312574  0.885518  0.261191      0.900667\n",
       "51  0.314046  0.885574  0.262736      0.904167\n",
       "52  0.313318  0.884963  0.257644      0.905000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d38773-8a41-417b-b21d-8bd860e6fb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate graphically\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "sns.lineplot(data=metrics[['accuracy', 'val_accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ba4f8b-4151-484a-9129-32cb47681517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.85      0.86      0.86      1000\n",
      "           3       0.90      0.91      0.90      1000\n",
      "           4       0.82      0.86      0.84      1000\n",
      "           5       0.98      0.98      0.98      1000\n",
      "           6       0.75      0.65      0.70      1000\n",
      "           7       0.96      0.96      0.96      1000\n",
      "           8       0.98      0.97      0.98      1000\n",
      "           9       0.96      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "\n",
      "[[889   1  14  22   5   1  64   0   4   0]\n",
      " [  0 972   0  21   3   0   2   0   2   0]\n",
      " [ 20   0 861  13  52   0  53   0   1   0]\n",
      " [ 13   1   9 913  32   0  31   0   1   0]\n",
      " [  1   1  49  24 863   0  60   0   2   0]\n",
      " [  0   0   0   0   0 980   0  14   0   6]\n",
      " [141   2  72  23 100   0 653   0   9   0]\n",
      " [  0   0   0   0   0  10   0 956   0  34]\n",
      " [  2   1   6   3   2   3   7   4 971   1]\n",
      " [  0   0   0   0   0   4   0  25   1 970]]\n"
     ]
    }
   ],
   "source": [
    "# Compute predicted classes and model performance metrics\n",
    "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6b774-99f9-4a20-bd42-9343b5754249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
